{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hate_speech_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YwUM7V6OewJ"
      },
      "source": [
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cqyGp3sQg0h",
        "outputId": "9c11b698-41e9-4f9b-d675-25258bb3232b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 63.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=18746d1ec8e645d730b8d06ed9505d0453c3dcaf7c227c118ff20fa4401fcae7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI4UAcYcOpxc",
        "outputId": "9946a804-d26c-4793-96c4-c9a59f5068c3"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\r\n",
        "from transformers import InputExample, InputFeatures\r\n",
        "\r\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mphpi40Qdyt",
        "outputId": "9479f204-3fb9-4927-afb2-ad0d2de05a69"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaTErsaJst7w"
      },
      "source": [
        "Read hate dataset and convert it into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd0PtS8gQqaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692d05db-dc7d-47ec-a2ff-51104b38d1ee"
      },
      "source": [
        "# df = pd.read_json('babi_new_12_train.json',orient='records')\r\n",
        "df = pd.read_csv(\"fox_h.csv\")\r\n",
        "df = df.drop(columns=['Unnamed: 0'])\r\n",
        "df.label.value_counts()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2186\n",
              "1     870\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Hc58BMrSVHYW",
        "outputId": "d015397a-df26-4a18-833f-6544c2551dbe"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>barryswallows Merkel would never say NO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PostApocalypticHero Expect more and more women...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>californiamojo Groping people in public wasn't...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MikeSte Merkel, possible the only person in ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>scientist They know very well, no means NO! Th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0            barryswallows Merkel would never say NO      1\n",
              "1  PostApocalypticHero Expect more and more women...      1\n",
              "2  californiamojo Groping people in public wasn't...      0\n",
              "3  MikeSte Merkel, possible the only person in ch...      1\n",
              "4  scientist They know very well, no means NO! Th...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSsSfaM0W2Ds"
      },
      "source": [
        "df1 = pd.read_csv('filtered_tweets.csv')\r\n",
        "df1 = df1.drop(columns=['Unnamed: 0'])\r\n",
        "df1.columns = ['text','label']\r\n",
        "df1.head()\r\n",
        "df1.label.value_counts()"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqMOovzpGOKD"
      },
      "source": [
        "df = df.append(df1)\r\n",
        "df.label.value_counts()"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zjTXZXeHWg0"
      },
      "source": [
        "df = df.sample(frac = 1) "
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgefoUK4RODW"
      },
      "source": [
        "msk = np.random.rand(len(df)) < 0.8\r\n",
        "\r\n",
        "train = df[msk]\r\n",
        "test = df[~msk]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs0yZKRGUefF",
        "outputId": "1bff9c67-9ade-4e57-84f1-57266b6c1b41"
      },
      "source": [
        "df.groupby('label')['label'].count()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    2186\n",
              "1     870\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7zqez7uUfky",
        "outputId": "7bdee0e5-33d0-49c4-84b1-9f408fe9a61d"
      },
      "source": [
        "train.groupby('label')['label'].count()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    1744\n",
              "1     702\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjBp7e80WqCQ",
        "outputId": "5c9e2ec1-48f7-4c33-cf2b-84200da12d3e"
      },
      "source": [
        "test.groupby('label')['label'].count()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    442\n",
              "1    168\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tomOu-V4Wrw-"
      },
      "source": [
        "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\r\n",
        "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\r\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "qdwNsE961nYm",
        "outputId": "b690084c-956d-43c9-9c1f-bc6226c92583"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>barryswallows Merkel would never say NO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PostApocalypticHero Expect more and more women...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>californiamojo Groping people in public wasn't...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MikeSte Merkel, possible the only person in ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>scientist They know very well, no means NO! Th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         DATA_COLUMN  LABEL_COLUMN\n",
              "0            barryswallows Merkel would never say NO             1\n",
              "1  PostApocalypticHero Expect more and more women...             1\n",
              "2  californiamojo Groping people in public wasn't...             0\n",
              "3  MikeSte Merkel, possible the only person in ch...             1\n",
              "4  scientist They know very well, no means NO! Th...             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "YnHfVRWF1pK2",
        "outputId": "2b63036d-ff8b-4e37-de44-950b4dd0956a"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>davidfair @quickfix GLOCK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Nevergofullliberal That's it pass more laws, y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Bunnysmind when no doesn't work...it is advisa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Lurch47 @reallynoway1 We're armed, Rufus!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>SSBN738G Do you really need a law to establish...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          DATA_COLUMN  LABEL_COLUMN\n",
              "21                         davidfair @quickfix GLOCK              1\n",
              "26  Nevergofullliberal That's it pass more laws, y...             0\n",
              "31  Bunnysmind when no doesn't work...it is advisa...             0\n",
              "38          Lurch47 @reallynoway1 We're armed, Rufus!             1\n",
              "39  SSBN738G Do you really need a law to establish...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cdRKItSW0Cz"
      },
      "source": [
        "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \r\n",
        "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n",
        "                                                          text_a = x[DATA_COLUMN], \r\n",
        "                                                          text_b = None,\r\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "\r\n",
        "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n",
        "                                                          text_a = x[DATA_COLUMN], \r\n",
        "                                                          text_b = None,\r\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "  \r\n",
        "  return train_InputExamples, validation_InputExamples\r\n",
        "\r\n",
        "  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \r\n",
        "                                                                           test, \r\n",
        "                                                                           'DATA_COLUMN', \r\n",
        "                                                                           'LABEL_COLUMN')\r\n",
        "  \r\n",
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\r\n",
        "    features = [] # -> will hold InputFeatures to be converted later\r\n",
        "\r\n",
        "    for e in examples:\r\n",
        "        # Documentation is really strong for this method, so please take a look at it\r\n",
        "        input_dict = tokenizer.encode_plus(\r\n",
        "            e.text_a,\r\n",
        "            add_special_tokens=True,\r\n",
        "            max_length=max_length, # truncates if len(s) > max_length\r\n",
        "            return_token_type_ids=True,\r\n",
        "            return_attention_mask=True,\r\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\r\n",
        "            truncation=True\r\n",
        "        )\r\n",
        "\r\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\r\n",
        "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\r\n",
        "\r\n",
        "        features.append(\r\n",
        "            InputFeatures(\r\n",
        "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\r\n",
        "            )\r\n",
        "        )\r\n",
        "\r\n",
        "    def gen():\r\n",
        "        for f in features:\r\n",
        "            yield (\r\n",
        "                {\r\n",
        "                    \"input_ids\": f.input_ids,\r\n",
        "                    \"attention_mask\": f.attention_mask,\r\n",
        "                    \"token_type_ids\": f.token_type_ids,\r\n",
        "                },\r\n",
        "                f.label,\r\n",
        "            )\r\n",
        "\r\n",
        "    return tf.data.Dataset.from_generator(\r\n",
        "        gen,\r\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\r\n",
        "        (\r\n",
        "            {\r\n",
        "                \"input_ids\": tf.TensorShape([None]),\r\n",
        "                \"attention_mask\": tf.TensorShape([None]),\r\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\r\n",
        "            },\r\n",
        "            tf.TensorShape([]),\r\n",
        "        ),\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "DATA_COLUMN = 'DATA_COLUMN'\r\n",
        "LABEL_COLUMN = 'LABEL_COLUMN'"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOm1oM-HXaby",
        "outputId": "62dae701-f191-463d-e870-e101e73cf4e3"
      },
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\r\n",
        "\r\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\r\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)\r\n",
        "\r\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\r\n",
        "validation_data = validation_data.batch(32)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX9Yig-5-PN_"
      },
      "source": [
        "# methods to calculate precision recall and f1\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "def recall_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    return recall\r\n",
        "\r\n",
        "def precision_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    return precision\r\n",
        "\r\n",
        "def f1_m(y_true, y_pred):\r\n",
        "    precision = precision_m(y_true, y_pred)\r\n",
        "    recall = recall_m(y_true, y_pred)\r\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujXS3VX8XjpE"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \r\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy'), recall_m, precision_m,f1_m])\r\n",
        "\r\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-ag54jH-ZLo"
      },
      "source": [
        "hist = model.fit(train_data, epochs=2, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JbBnCyTtBvq"
      },
      "source": [
        "Read movie subtitle cleansed data and pass for prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWO0Gd0kJcjc"
      },
      "source": [
        "df_bb = pd.read_csv('bad_boys.csv')\r\n",
        "df_md = pd.read_csv('mrsDoubtfire_cleansed.csv')\r\n",
        "df_bk = pd.read_csv('blackkklanman_cleansed.csv')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "XAsCNx8NTsVB",
        "outputId": "350e3591-840e-47a9-d7c5-98f8b73af945"
      },
      "source": [
        "df_bk.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>﻿Have you seen Dr. Meade?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Dr. Meade!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Oh, can you help me find Dr. Meade?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>God, help us.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>God, save the Confederacy!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                            sentences\n",
              "0           0            ﻿Have you seen Dr. Meade?\n",
              "1           1                           Dr. Meade!\n",
              "2           2  Oh, can you help me find Dr. Meade?\n",
              "3           3                        God, help us.\n",
              "4           4           God, save the Confederacy!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "x8LVTY-zEJPV",
        "outputId": "8141015c-7690-49e4-b4d9-850a67100434"
      },
      "source": [
        "df_md.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Figaro, Figaro, Figaro, Figaro, Figaro, Figaro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Ah bravo Figaro, bravo bravissimo, ah bravo Fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Salutations, snack.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yipe. On second thought.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yiiipe!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                          sentences\n",
              "0           0  Figaro, Figaro, Figaro, Figaro, Figaro, Figaro...\n",
              "1           1  Ah bravo Figaro, bravo bravissimo, ah bravo Fi...\n",
              "2           2                                Salutations, snack.\n",
              "3           3                           Yipe. On second thought.\n",
              "4           4                                            Yiiipe!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "5t5fCj1kEK3q",
        "outputId": "9ae0957a-9c3b-4e42-b2ef-716c319f4a0e"
      },
      "source": [
        "df_bb.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mike! What the hell are you doing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's called driving, Marcus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Slow down.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What? Four minutes?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Speed up.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                   0\n",
              "0           0  Mike! What the hell are you doing?\n",
              "1           1        It's called driving, Marcus.\n",
              "2           2                          Slow down.\n",
              "3           3                 What? Four minutes?\n",
              "4           4                           Speed up."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08HarZ4TrHr"
      },
      "source": [
        "pred_sents_bb = df_bb['0'].to_list()\r\n",
        "pred_sents_bk = df_bk['sentences'].to_list()\r\n",
        "pred_sents_md = df_md['sentences'].to_list()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIOUNZWwJ9iO",
        "outputId": "2e6efa55-c057-498e-e616-54cf6150604a"
      },
      "source": [
        "pred_sents_bk[:5]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffHave you seen Dr. Meade?',\n",
              " 'Dr. Meade!',\n",
              " 'Oh, can you help me find Dr. Meade?',\n",
              " 'God, help us.',\n",
              " 'God, save the Confederacy!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY6FLB4_YcDp"
      },
      "source": [
        "def get_annotated_sents(pred_sents_bk, name):\r\n",
        "  last=0\r\n",
        "  label=0\r\n",
        "  df_pred = pd.DataFrame(columns=['sentence','label'])\r\n",
        "  for i in range(32,len(pred_sents_bk),32):\r\n",
        "    tf_batch = tokenizer(pred_sents_bk[last:i], max_length=128, padding=True, truncation=True, return_tensors='tf')\r\n",
        "    tf_outputs = model(tf_batch)\r\n",
        "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\r\n",
        "    labels = ['0','1']\r\n",
        "    label = tf.argmax(tf_predictions, axis=1)\r\n",
        "    label = label.numpy()\r\n",
        "    \r\n",
        "    for j in range(32):\r\n",
        "      df_pred.loc[len(df_pred.index)] = [pred_sents_bk[last+j],label[j]]\r\n",
        "\r\n",
        "    last=i\r\n",
        "\r\n",
        "  df_pred.to_csv(name)\r\n",
        "  return df_pred\r\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbKfz06StRPd"
      },
      "source": [
        "Save output to a csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBIfprF-PK1A"
      },
      "source": [
        "get_annotated_sents(pred_sents_bk, 'blackklans_bert_fox_tweet.csv')\r\n",
        "get_annotated_sents(pred_sents_md, 'mrsdoubtfire_bert_fox_tweet.csv')\r\n",
        "df_bb_p = get_annotated_sents(pred_sents_bb, 'badboys_bert_fox_tweet.csv')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QM5SNohNAzB"
      },
      "source": [
        "Combination of fox and tweets:\r\n",
        "\r\n",
        "\r\n",
        "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\r\n",
        "1394/1394 [==============================] - 693s 487ms/step - loss: 0.1490 - accuracy: 0.9491 - recall_m: 0.6663 - precision_m: 0.0603 - f1_m: 0.1085 - val_loss: 0.1515 - val_accuracy: 0.9502 - val_recall_m: 0.7645 - val_precision_m: 0.0697 - val_f1_m: 0.1247\r\n",
        "\r\n",
        "\r\n",
        "Epoch 2/2\r\n",
        "1394/1394 [==============================] - 679s 487ms/step - loss: 0.0707 - accuracy: 0.9768 - recall_m: 0.8151 - precision_m: 0.0716 - f1_m: 0.1289 - val_loss: 0.2617 - val_accuracy: 0.9440 - val_recall_m: 0.8742 - val_precision_m: 0.0795 - val_f1_m: 0.1428"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqnlsuK5N5af"
      },
      "source": [
        "Using Fox:\r\n",
        "\r\n",
        "Epoch 1/2\r\n",
        "154/154 [==============================] - 90s 497ms/step - loss: 0.5193 - accuracy: 0.7430 - recall_m: 0.2178 - precision_m: 0.1383 - f1_m: 0.1427 - val_loss: 0.1773 - val_accuracy: 0.9459 - val_recall_m: 0.9550 - val_precision_m: 0.2825 - val_f1_m: 0.4219\r\n",
        "\r\n",
        "\r\n",
        "Epoch 2/2\r\n",
        "154/154 [==============================] - 75s 485ms/step - loss: 0.0683 - accuracy: 0.9761 - recall_m: 0.9528 - precision_m: 0.2948 - f1_m: 0.4390 - val_loss: 0.0943 - val_accuracy: 0.9770 - val_recall_m: 0.9713 - val_precision_m: 0.2819 - val_f1_m: 0.4228"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbbMIIu6N8Ge"
      },
      "source": [
        "Using Tweets:\r\n",
        "\r\n",
        "Epoch 1/2\r\n",
        "1236/1236 [==============================] - 1073s 857ms/step - loss: 0.1077 - accuracy: 0.9604 - recall_m: 0.6087 - precision_m: 0.0475 - f1_m: 0.0856 - val_loss: 0.2212 - val_accuracy: 0.9445 - val_recall_m: 0.7309 - val_precision_m: 0.0520 - val_f1_m: 0.0949\r\n",
        "\r\n",
        "Epoch 2/2\r\n",
        "1236/1236 [==============================] - 1058s 856ms/step - loss: 0.0478 - accuracy: 0.9838 - recall_m: 0.7175 - precision_m: 0.0576 - f1_m: 0.1042 - val_loss: 0.2836 - val_accuracy: 0.9369 - val_recall_m: 0.7539 - val_precision_m: 0.0540 - val_f1_m: 0.0985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI11AYZvG__1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}