{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests\n",
    "#from Preprocessing import clean_text, remove_names, entity_recognizing, remove_url\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  label  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\student\\Desktop\\IAS\\SEMESTER 3\\NLP and Web\\Project\\movie_hatespeech_detection\\labeled_data.csv'\n",
    "df_training = pd.read_csv(path)\n",
    "df_training = df_training.rename(columns={'class': 'label'})\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4162\n",
       "0     1430\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:ylabel='label'>], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_training.label.value_counts().plot(kind='pie', subplots=True, title='Hate Speech Distribution Twitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_training = df_training[['class','tweet']]\n",
    "# df_training.replace({'class' : { 0 : 1, 1 : 0, 2 : 0 }},inplace=True)\n",
    "# df_training['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hatespeech_tweets(df):\n",
    "    \n",
    "    def filter_tweets(tweet):\n",
    "        return re.sub('@.\\:|!|@\\w+:|@[\\w]*|&#[0-9]*;|#\\w+|RT|\\/\\/t.co\\/\\w+|&gt|&lt', '', tweet)\n",
    "\n",
    "    def postprocess_filter_tweets(tweet):\n",
    "        \n",
    "        return df\n",
    "\n",
    "    df['tweet'] = df['tweet'].apply(filter_tweets)\n",
    "    df.replace(\"\", np.nan, inplace=True)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_training = filter_hatespeech_tweets(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to lower-case\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  label  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0     as a woman you shouldn't complain about cle...  \n",
      "1     boy dats cold...tyga dwn bad for cuffin dat...  \n",
      "2     dawg   you ever fuck a bitch and she start ...  \n",
      "3                             she look like a tranny  \n",
      "4     the shit you hear about me might be true or...  \n"
     ]
    }
   ],
   "source": [
    "TEXT_COLUMN = \"tweet\"\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "print(\"Converting to lower-case\")\n",
    "df_training[TEXT_COLUMN] = df_training[TEXT_COLUMN].str.lower()\n",
    "print(df_training.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training['doc_len'] = df_training[TEXT_COLUMN].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(df_training['doc_len'].mean() + df_training['doc_len'].std()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>doc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>as a woman you shouldn't complain about cle...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>boy dats cold...tyga dwn bad for cuffin dat...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dawg   you ever fuck a bitch and she start ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>she look like a tranny</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the shit you hear about me might be true or...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  label  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  doc_len  \n",
       "0     as a woman you shouldn't complain about cle...       25  \n",
       "1     boy dats cold...tyga dwn bad for cuffin dat...       16  \n",
       "2     dawg   you ever fuck a bitch and she start ...       21  \n",
       "3                             she look like a tranny        9  \n",
       "4     the shit you hear about me might be true or...       26  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 11\n",
    "test_size = 0.2\n",
    "def split_dataset(df, seed, test_size):\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=seed, shuffle=True)\n",
    "    return train.tweet, train.label, test.tweet, test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, test, test_targets = split_dataset(df_training, seed=seed, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300  # how big is each word vector\n",
    "max_features = None  # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = max_seq_len  # max number of words in a question to use #99.99%\n",
    "\n",
    "def encode(data, label):\n",
    "    # fill up the missing values\n",
    "    X = data.fillna(\"_na_\").values\n",
    "    \n",
    "    # Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "    tokenizer.fit_on_texts(list(X))\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    # Pad the sentences\n",
    "    X = pad_sequences(X, maxlen=maxlen)\n",
    "    print(X.shape)\n",
    "    \n",
    "    # Get the target values\n",
    "    y = pd.get_dummies(label.values)\n",
    "    print(y.shape)\n",
    "    #le = LabelEncoder()\n",
    "    #le.fit(Y_train)\n",
    "    #encoded_Y = le.transform(Y_train)\n",
    "    return X,y,vocab_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19825, 21)\n",
      "(19825, 3)\n",
      "(4957, 21)\n",
      "(4957, 3)\n"
     ]
    }
   ],
   "source": [
    "# FETCH DATA, LABELS, DICTIONARIES\n",
    "X_train, y_train, train_dictionary_size = encode(train, train_targets)\n",
    "X_test, y_test, test_dictionary_size = encode(test, test_targets)\n",
    "total_vocab_size = train_dictionary_size + test_dictionary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19821</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19822</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19824</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19825 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2\n",
       "0      0  1  0\n",
       "1      0  1  0\n",
       "2      0  0  1\n",
       "3      0  1  0\n",
       "4      0  1  0\n",
       "...   .. .. ..\n",
       "19820  0  1  0\n",
       "19821  0  1  0\n",
       "19822  0  1  0\n",
       "19823  0  1  0\n",
       "19824  0  1  0\n",
       "\n",
       "[19825 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, embed_size, input_length=X_train.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(total_vocab_size, embed_size, input_length=X_train.shape[1]),\n",
    "        tf.keras.layers.LSTM(256),\n",
    "        tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "  ])\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 21, 300)           11406000  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 256)               570368    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 11,977,139\n",
      "Trainable params: 11,977,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 28/620 [>.............................] - ETA: 3:07 - loss: 0.0944 - accuracy: 0.9699 - precision_7: 0.9709 - recall_7: 0.9688"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "#history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "      epochs=epochs,  \n",
    "      verbose=1, \n",
    "      validation_data=(X_test, y_test),\n",
    "      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
